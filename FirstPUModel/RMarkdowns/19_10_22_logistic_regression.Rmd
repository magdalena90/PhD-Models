---
title: 'Logistic Regression'
output:
  html_document:
    code_folding: 'hide'
---

```{r load_packages, warning=FALSE, message=FALSE}

library(tidyverse)
library(knitr)
library(plotly) ; library(viridis) ; library(gridExtra) ; library(RColorBrewer)
library(Rtsne)
library(knitr)
```

## Load and prepare data

Load dataset (preprocessing code in 19_10_11_create_dataset.Rmd)
```{r selecting_clustering}

clustering_selected = 'DynamicHybridMergedSmall'
print(paste0('Using clustering ', clustering_selected))

# Dataset created with DynamicTreeMerged algorithm
dataset = read.csv(paste0('./../Data/Gandal/dataset_', clustering_selected, '.csv'), row.names=1)
```

#### Gene filtering:

- Remove genes without cluster (Module=gray)

- Remove genes with Module-Trait correlation missing

```{r}
rm_cluster = dataset[is.na(dataset$MTcor),clustering_selected] %>% unique %>% as.character

print(paste0('Removing ', sum(dataset[,clustering_selected]=='gray'), ' genes without cluster'))

print(paste0('Removing ', sum(is.na(dataset$MTcor)), ' genes belonging to module(s) without module-trait correlation: ',
             rm_cluster))

new_dataset = dataset %>% filter(dataset[,clustering_selected]!='gray' & !is.na(MTcor))
```

#### Variable changes:

- Using Module Membership variables instead of binary module membership

- Not including p-value variables

- Including a new variable with the absolute value of GS

- Removing information from gray module (unclassified genes) and any other module that did not have a Module-Trait value

- Objective variable: Binary label indicating if it's in the SFARI dataset or not (including score 6)

```{r}
new_dataset = new_dataset %>% dplyr::select(-c(matches(paste('pval', clustering_selected,
                                               gsub('#','',rm_cluster), sep='|')), MMgray)) %>%
              mutate('absGS'=abs(GS), 'SFARI'=ifelse(gene.score=='None', FALSE, TRUE)) %>%
              dplyr::select(-gene.score)

rownames(new_dataset) = rownames(dataset)[!is.na(dataset$MTcor) & dataset[,clustering_selected]!='gray']

rm(rm_cluster)
```

```{r}
original_dataset = dataset
dataset = new_dataset
print(paste0('The final dataset contains ', nrow(dataset), ' observations and ', ncol(dataset), ' variables.'))
rm(new_dataset)
```

Sample of the dataset
```{r}
dataset %>% head %>% kable
```

Objective variable distribution: Unbalanced labels
```{r}
print(table(dataset$SFARI))

cat(paste0('\n',round(mean(dataset$SFARI)*100,2), '% of the observations are positive'))
```

---

## Visualisations

### Visualising the variables

Chose the t-SNE algorithm because it preserves distances

The SFARI labels is still close to the absolute value of Gene Significance. This time the MM variables seem to be grouped in 3 clusters
```{r tsne_variables, warning=FALSE}
tsne = dataset %>% t %>% Rtsne(perplexity=10)

plot_data = data.frame('ID'=colnames(dataset), 'C1'=tsne$Y[,1], 'C2'=tsne$Y[,2],
                       type=ifelse(grepl('MM', colnames(dataset)),'ModMembership',
                            ifelse(grepl('SFARI', colnames(dataset)), 'SFARI',
                            ifelse(grepl('GS', colnames(dataset)), 'GS', 'MTcor'))))

ggplotly(plot_data %>% ggplot(aes(C1, C2, color=type)) + geom_point(aes(id=ID)) + 
         theme_minimal() + ggtitle('t-SNE visualisation of variables'))
```

The Module Membership variables are grouped by Module-Trait correlation, with positive correlations on one side, negative on the other, and modules with low correlation far away from the SFARI tag
```{r tsne_mtcor_variables, warning=FALSE}
mtcor_by_module = original_dataset %>% dplyr::select(matches(clustering_selected), MTcor) %>% unique
colnames(mtcor_by_module) = c('ID','MTcor')

plot_data = mtcor_by_module %>% mutate(ID = gsub('#','MM.',ID)) %>% right_join(plot_data, by='ID')

ggplotly(plot_data %>% ggplot(aes(C1, C2, color=MTcor)) + geom_point(aes(id=ID)) + 
         scale_color_viridis() + theme_minimal() + 
         ggtitle('t-SNE of variables coloured by Module-Diagnosis correlation'))

rm(mtcor_by_module, tsne)
```

### Visualising the observations

```{r pca_obs, fig.width=10, fig.height=10, warning=FALSE}

# Mean Expression data
load('./../Data/Gandal/preprocessed_data.RData')
datExpr = datExpr %>% data.frame
mean_expr = data.frame('ID'=rownames(datExpr), 'meanExpr' = rowMeans(datExpr))

# PCA
pca = dataset %>% t %>% prcomp

plot_data = data.frame('ID'=rownames(dataset), 'PC1'=pca$rotation[,1], 'PC2'=pca$rotation[,2], 
                       'SFARI'=dataset$SFARI, 'MTcor'=dataset$MTcor, 'GS'=dataset$GS) %>%
            mutate(alpha=ifelse(SFARI, 0.7, 0.2)) %>% left_join(mean_expr, by='ID')

p1 = plot_data %>% ggplot(aes(PC1, PC2, color=MTcor)) + geom_point(alpha=0.7) + scale_color_viridis() + 
     theme_minimal() + ggtitle('Genes coloured by Module-Diagnosis correlation') +
     xlab(paste0('PC1 (',round(100*summary(pca)$importance[2,1]),'%)')) +
     ylab(paste0('PC2 (',round(100*summary(pca)$importance[2,2]),'%)')) +
     theme(legend.position='bottom')

p2 = plot_data %>% ggplot(aes(PC1, PC2, color=GS)) + geom_point(alpha=0.5) + scale_color_viridis() + 
     theme_minimal() + ggtitle('Genes coloured by Gene Significance') + theme(legend.position='bottom')

p3 = plot_data %>% ggplot(aes(PC1, PC2, color=SFARI)) + geom_point(aes(alpha=alpha)) +
     theme_minimal() + ggtitle('Genes coloured by SFARI label') + theme(legend.position='bottom')
p3 = ggExtra::ggMarginal(p3, type='density', groupColour=TRUE, size=10)

p4 = plot_data %>% ggplot(aes(PC1, PC2, color=meanExpr)) + geom_point(alpha=0.5) + scale_color_viridis() + 
     theme_minimal() + ggtitle('Genes coloured by mean level of expression') + theme(legend.position='bottom')

grid.arrange(p1, p2, p3, p4, nrow=2)


rm(pca, datExpr, datGenes, datMeta, dds, DE_info, mean_expr, p1, p2, p3, p4)
```

---

## Resampling to reduce class imbalance

**Should check SMOTE (Synthetic Minority Over-sampling Technique) method for later**

Aiming for 1:2 ratio in labels (a bit arbitrary, but I was thinking that 1/3-2/3 doesn't sound as imbalanced and this way I don't have to remove that many genes or over-sample so much as with a 1:1 relation)

Under-sampling observations with negative SFARI labels: Keep 1/3 of the negative class
```{r}
negative_obs = which(!dataset$SFARI)
remove_obs = sample(negative_obs, size=floor(length(negative_obs)*2/3))

dataset = dataset[-remove_obs,]

rm(negative_obs, remove_obs)
```

Over-sampling observations with positive SFARI label: Sample with replacement 3x original number of observations

Need to divide first into train and test sets to keep the sets independent
```{r}
set.seed(123)
train_idx = sample(1:nrow(dataset), size=floor(0.8*nrow(dataset)))
train_set = dataset[train_idx,]
test_set = dataset[-train_idx,]

rm(train_idx)
```

Sample with replacement positive observations in train set
```{r}
positive_obs = which(train_set$SFARI)
add_obs = sample(positive_obs, size=2*length(positive_obs), replace=TRUE)

train_set = train_set[c(1:nrow(train_set), add_obs),]

rm(positive_obs, add_obs)
```

```{r}
table(train_set$SFARI)
```

---

## Logistic Regression

### Train model
```{r}
library(ROCR)

train_set$SFARI = train_set$SFARI %>% as.factor

fit = glm(SFARI~., data=train_set, family='binomial')
test_set$pred = predict(fit, newdata=test_set, type='response')
```


### Test model

Using AUC instead of accuracy to measure the performance of the model because of the imbalance between classes
```{r ROC}
pred_ROCR = prediction(test_set$pred, test_set$SFARI)
roc_ROCR = performance(pred_ROCR, measure='tpr', x.measure='fpr')
AUC = performance(pred_ROCR, measure='auc')@y.values[[1]]

plot(roc_ROCR, main=paste0('ROC curve (AUC=',round(AUC,2),')'), col='#009999')
abline(a=0, b=1, col='#666666')

lift_ROCR = performance(pred_ROCR, measure='lift', x.measure='rpp')
plot(lift_ROCR, main='Lift curve', col='#86b300')

rm(pred_ROCR, roc_ROCR, AUC, lift_ROCR)
```

### Analyse model

SFARI genes have a slightly higher distribution than the rest
```{r}
plot_data = test_set %>% dplyr::select(pred, SFARI)

plot_data %>% ggplot(aes(pred, fill=SFARI, color=SFARI)) + geom_density(alpha=0.3) + 
              theme_minimal() + ggtitle('Predicted score distribution by SFARI label')
```

Gene significance doesn't seem to be relevant for the model
```{r}
summary(fit)
```

There doesn't seem to be a relation between the modules' coefficient and their correlation with Diagnosis, although there is correlation between the variables, so it's not correct to analyse their coefficients when this happens

Also, this results changes a lot between different runs
```{r, warning=FALSE}
var_fit_info = summary(fit)$coefficients %>% as.data.frame %>% 
               mutate(signif=`Pr(>|z|)`<0.05, ID=rownames(summary(fit)$coefficients))

plot_data = original_dataset %>% dplyr::select(matches(clustering_selected), MTcor) 
colnames(plot_data) = c('ID','MTcor')

plot_data = plot_data %>% mutate(ID=gsub('#','MM.',ID)) %>% group_by(ID, MTcor) %>% 
            tally %>% inner_join(var_fit_info, by='ID')

ggplotly(plot_data %>% ggplot(aes(Estimate, MTcor, color=signif, size=n)) + geom_point(aes(id=ID)) + 
         geom_smooth(method='lm', se=FALSE) + theme_minimal() +
         xlab('Coefficient in regression') + ylab('Module-Diagnosis correlation'))

rm(var_fit_info)
```

Strong correlations between variables
```{r, fig.width=10, fig.height=10}
cors = cor(train_set[,-ncol(train_set)])
heatmap.2(cors, dendrogram='none', col=brewer.pal(11,'RdBu'), scale='none', trace='none')
rm(cors)
```

Print genes with highest scores in test set
```{r}
test_set %>% dplyr::select(pred, SFARI) %>% mutate(ID = rownames(test_set)) %>% 
             arrange(desc(pred)) %>% top_n(50, wt=pred) %>% dplyr::select(ID, SFARI, pred) %>%
             kable
```
